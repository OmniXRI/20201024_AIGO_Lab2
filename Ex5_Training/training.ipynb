{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF03nS9IfKlQ"
      },
      "source": [
        "\n",
        "從YOLO官網下載YOLOv3的預訓練權重檔"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VwnuCvrgSoS"
      },
      "source": [
        "!git clone https://github.com/OmniXRI/OpenVINO_RealSense_HarvestBot.git #取得小蕃茄影像及標註資料集\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg4sP3XJhnCh"
      },
      "source": [
        "切換至工具路徑 my_yolo3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOnl--bSggDJ"
      },
      "source": [
        "%cd OpenVINO_RealSense_HarvestBot\n",
        "%cd my_yolo3/\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjzX3pCfhzTU"
      },
      "source": [
        "到YOLO官網下載預設權重檔 yolov3.weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnBkXKivfLBP"
      },
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6EncFp7iFQ6"
      },
      "source": [
        "展開 my_voc_annotation.py 原始碼"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ3E1VpVui4w"
      },
      "source": [
        "%pycat my_voc_annotation.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZqPP_N0iSN5"
      },
      "source": [
        "my_voc_annotation.py 原始碼，將標註好的VOC格式檔案轉成YOLO格式。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CwzmjZAwMPz"
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "from os import getcwd\n",
        "\n",
        "sets=['train', 'val', 'test'] #定義資料集名稱\n",
        "\n",
        "classes = [\"tomato\"] #定義自訂義類別名稱\n",
        "\n",
        "def convert_annotation(img_id, list_file):\n",
        "    in_file = open('VOC2007/Annotations/%s.xml' %img_id, encoding='utf-8') #指定標註檔路徑\n",
        "    tree=ET.parse(in_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    for obj in root.iter('object'):\n",
        "        difficult = obj.find('difficult').text\n",
        "        cls = obj.find('name').text\n",
        "        if cls not in classes or int(difficult)==1:\n",
        "            continue\n",
        "        cls_id = classes.index(cls)\n",
        "        xmlbox = obj.find('bndbox')\n",
        "        b = (int(xmlbox.find('xmin').text), int(xmlbox.find('ymin').text), int(xmlbox.find('xmax').text), int(xmlbox.find('ymax').text))\n",
        "        list_file.write(\" \" + \",\".join([str(a) for a in b]) + ',' + str(cls_id))\n",
        "\n",
        "for image_set in sets:\n",
        "    img_names = open('VOC2007/ImageSets/Main/%s.txt'%image_set).read().strip().split() #指定待轉換清單檔案名稱\n",
        "    list_file = open('2007_%s.txt'%image_set, 'w') #指定轉換完成清單名稱\n",
        "    for img_name in img_names:\n",
        "        list_file.write('VOC2007/JPEGImages/%s.jpg'%img_name)\n",
        "        img_id = img_name.split('.')\n",
        "        convert_annotation(img_id[0], list_file)\n",
        "        list_file.write('\\n')\n",
        "    list_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf49pQEPig0i"
      },
      "source": [
        "檢查是否有正確轉出 2007_test.txt, 2007_train.txt, 2007_val.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EI527-aovYHe"
      },
      "source": [
        "!date\n",
        "!ls *.txt -all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT7gsRqBi9Pf"
      },
      "source": [
        "將YOLOv3權重檔轉換為keras格式(*.h5)，命名為 yolo_weights.h5存放至model_data路徑下。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sFGkbghwkjQ"
      },
      "source": [
        "!python convert.py -w yolov3.cfg yolov3.weights model_data/yolo_weights.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P54uhvJyjTkw"
      },
      "source": [
        "展開 my_train.py 程式碼"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0E1foCkxPkF"
      },
      "source": [
        "%pycat my_train.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfASn3T-jZTe"
      },
      "source": [
        "my_train.py 原始碼，負責訓練模型參數。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEd9GysRxj0o"
      },
      "source": [
        "import numpy as np\n",
        "import keras.backend as K\n",
        "from keras.layers import Input, Lambda\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
        "from yolo3.utils import get_random_data\n",
        "\n",
        "\n",
        "def _main():\n",
        "    annotation_path = '2007_train.txt' #待訓練清單(YOLO格式）\n",
        "    log_dir = 'logs/000/' #訓練過程及結果暫存路徑\n",
        "    classes_path = 'model_data/my_classes.txt' #自定義標籤檔路徑及名稱\n",
        "    anchors_path = 'model_data/yolo_anchors.txt' #錨點定義檔路徑及名稱\n",
        "    class_names = get_classes(classes_path)\n",
        "    num_classes = len(class_names)\n",
        "    anchors = get_anchors(anchors_path)\n",
        "\n",
        "    input_shape = (416,416) # multiple of 32, hw 預設輸入影像尺寸須為32的倍數(寬，高)\n",
        "\n",
        "    is_tiny_version = len(anchors)==6 # default setting\n",
        "    if is_tiny_version:\n",
        "        model = create_tiny_model(input_shape, anchors, num_classes,\n",
        "            freeze_body=2, weights_path='model_data/tiny_yolo_weights.h5')\n",
        "    else:\n",
        "        model = create_model(input_shape, anchors, num_classes,\n",
        "            freeze_body=2, weights_path='model_data/yolo_weights.h5') #指定起始訓練權重檔路徑及名稱\n",
        "        \n",
        "    logging = TensorBoard(log_dir=log_dir)\n",
        "    checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
        "        monitor='val_loss', save_weights_only=True, save_best_only=True, period=3) #訓練過程權重檔名稱由第幾輪加上損失率為名稱\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
        "\n",
        "    val_split = 0.1\n",
        "    with open(annotation_path) as f:\n",
        "        lines = f.readlines()\n",
        "    np.random.seed(10101)\n",
        "    np.random.shuffle(lines)\n",
        "    np.random.seed(None)\n",
        "    num_val = int(len(lines)*val_split)\n",
        "    num_train = len(lines) - num_val\n",
        "\n",
        "    # Train with frozen layers first, to get a stable loss.\n",
        "    # Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n",
        "    if True:\n",
        "        model.compile(optimizer=Adam(lr=1e-3), loss={\n",
        "            # use custom yolo_loss Lambda layer.\n",
        "            'yolo_loss': lambda y_true, y_pred: y_pred})\n",
        "\n",
        "        batch_size = 24 #批次處理數量，依GPU記憶體大小決定\n",
        "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
        "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
        "                steps_per_epoch=max(1, num_train//batch_size),\n",
        "                validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
        "                validation_steps=max(1, num_val//batch_size),\n",
        "                epochs=50, #訓練遍歷次數\n",
        "                initial_epoch=0, #初始訓練遍歷次數\n",
        "                callbacks=[logging, checkpoint])\n",
        "    \n",
        "        model.save_weights(log_dir + 'trained_weights_stage_1.h5') #儲存臨時權重檔案名稱\n",
        "\n",
        "    # 解凍並繼續訓練以進行微調\n",
        "    # 如果效果不好則訓練更長時間\n",
        "    if True:\n",
        "        for i in range(len(model.layers)):\n",
        "            model.layers[i].trainable = True\n",
        "        model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
        "        print('Unfreeze all of the layers.')\n",
        "\n",
        "        batch_size = 24 # note that more GPU memory is required after unfreezing the body\n",
        "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
        "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
        "            steps_per_epoch=max(1, num_train//batch_size),\n",
        "            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
        "            validation_steps=max(1, num_val//batch_size),\n",
        "            epochs=100, #訓練遍歷次數\n",
        "            initial_epoch=50, #初始訓練遍歷次數\n",
        "            callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
        "        \n",
        "        model.save_weights(log_dir + 'trained_weights_final.h5') #儲存最終權重檔\n",
        "        #model.save(log_dir + 'trained_model_final.h5') #儲存完整模型及權重檔\n",
        "\n",
        "    # Further training if needed.\n",
        "\n",
        "\n",
        "def get_classes(classes_path):\n",
        "    '''loads the classes'''\n",
        "    with open(classes_path) as f:\n",
        "        class_names = f.readlines()\n",
        "    class_names = [c.strip() for c in class_names]\n",
        "    return class_names\n",
        "\n",
        "def get_anchors(anchors_path):\n",
        "    '''loads the anchors from a file'''\n",
        "    with open(anchors_path) as f:\n",
        "        anchors = f.readline()\n",
        "    anchors = [float(x) for x in anchors.split(',')]\n",
        "    return np.array(anchors).reshape(-1, 2)\n",
        "\n",
        "\n",
        "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
        "            weights_path='model_data/yolo_weights.h5'):\n",
        "    '''create the training model'''\n",
        "    K.clear_session() # get a new session\n",
        "    image_input = Input(shape=(None, None, 3))\n",
        "    h, w = input_shape\n",
        "    num_anchors = len(anchors)\n",
        "\n",
        "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
        "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
        "\n",
        "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
        "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
        "\n",
        "    if load_pretrained:\n",
        "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
        "        print('Load weights {}.'.format(weights_path))\n",
        "        if freeze_body in [1, 2]:\n",
        "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
        "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
        "            for i in range(num): model_body.layers[i].trainable = False\n",
        "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
        "\n",
        "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
        "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
        "        [*model_body.output, *y_true])\n",
        "    model = Model([model_body.input, *y_true], model_loss)\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
        "            weights_path='model_data/tiny_yolo_weights.h5'):\n",
        "    '''create the training model, for Tiny YOLOv3'''\n",
        "    K.clear_session() # get a new session\n",
        "    image_input = Input(shape=(None, None, 3))\n",
        "    h, w = input_shape\n",
        "    num_anchors = len(anchors)\n",
        "\n",
        "    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n",
        "        num_anchors//2, num_classes+5)) for l in range(2)]\n",
        "\n",
        "    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n",
        "    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
        "\n",
        "    if load_pretrained:\n",
        "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
        "        print('Load weights {}.'.format(weights_path))\n",
        "        if freeze_body in [1, 2]:\n",
        "            # Freeze the darknet body or freeze all but 2 output layers.\n",
        "            num = (20, len(model_body.layers)-2)[freeze_body-1]\n",
        "            for i in range(num): model_body.layers[i].trainable = False\n",
        "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
        "\n",
        "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
        "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n",
        "        [*model_body.output, *y_true])\n",
        "    model = Model([model_body.input, *y_true], model_loss)\n",
        "\n",
        "    return model\n",
        "\n",
        "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
        "    '''data generator for fit_generator'''\n",
        "    n = len(annotation_lines)\n",
        "    i = 0\n",
        "    while True:\n",
        "        image_data = []\n",
        "        box_data = []\n",
        "        for b in range(batch_size):\n",
        "            if i==0:\n",
        "                np.random.shuffle(annotation_lines)\n",
        "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
        "            image_data.append(image)\n",
        "            box_data.append(box)\n",
        "            i = (i+1) % n\n",
        "        image_data = np.array(image_data)\n",
        "        box_data = np.array(box_data)\n",
        "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
        "        yield [image_data, *y_true], np.zeros(batch_size)\n",
        "\n",
        "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
        "    n = len(annotation_lines)\n",
        "    if n==0 or batch_size<=0: return None\n",
        "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    _main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBuEMFVDjwcr"
      },
      "source": [
        "檢查是否順利完成訓練，產出 trained_weights_final.h5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1EyErTXCjs4"
      },
      "source": [
        "!ls model_data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isHgjwIVkIKA"
      },
      "source": [
        "展開 my_yolo.py 程式碼"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5IHM2Q52vRb"
      },
      "source": [
        "%pycat my_yolo.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD3Zx4FtkMe3"
      },
      "source": [
        "my_yolo.py 原始碼，負責最終影像推論。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spe5R_Qi3KPd"
      },
      "source": [
        "import colorsys\n",
        "import os\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "from keras.layers import Input\n",
        "from PIL import Image, ImageFont, ImageDraw\n",
        "\n",
        "from yolo3.model import yolo_eval, yolo_body, tiny_yolo_body\n",
        "from yolo3.utils import letterbox_image\n",
        "import os\n",
        "from keras.utils import multi_gpu_model\n",
        "\n",
        "class YOLO(object):\n",
        "    _defaults = {\n",
        "        \"model_path\": 'model_data/trained_weights_final.h5', #指定YOLO訓練完成權重檔路徑及名稱\n",
        "        \"anchors_path\": 'model_data/yolo_anchors.txt', #指定錨點定義檔路徑及名稱\n",
        "        \"classes_path\": 'model_data/my_classes.txt', #指定自定義標籤檔路徑及名稱\n",
        "        \"score\" : 0.1, #最低置信度門檻(0.01~0.99)\n",
        "        \"iou\" : 0.45, #重疊區比例(0.01~1.0)\n",
        "        \"model_image_size\" : (416, 416), #影像尺寸\n",
        "        \"gpu_num\" : 1, #使用GPU數量\n",
        "    }\n",
        "\n",
        "    @classmethod\n",
        "    def get_defaults(cls, n):\n",
        "        if n in cls._defaults:\n",
        "            return cls._defaults[n]\n",
        "        else:\n",
        "            return \"Unrecognized attribute name '\" + n + \"'\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        self.__dict__.update(self._defaults) # set up default values\n",
        "        self.__dict__.update(kwargs) # and update with user overrides\n",
        "        self.class_names = self._get_class()\n",
        "        self.anchors = self._get_anchors()\n",
        "        self.sess = K.get_session()\n",
        "        self.boxes, self.scores, self.classes = self.generate()\n",
        "\n",
        "    def _get_class(self):\n",
        "        classes_path = os.path.expanduser(self.classes_path)\n",
        "        with open(classes_path) as f:\n",
        "            class_names = f.readlines()\n",
        "        class_names = [c.strip() for c in class_names]\n",
        "        return class_names\n",
        "\n",
        "    def _get_anchors(self):\n",
        "        anchors_path = os.path.expanduser(self.anchors_path)\n",
        "        with open(anchors_path) as f:\n",
        "            anchors = f.readline()\n",
        "        anchors = [float(x) for x in anchors.split(',')]\n",
        "        return np.array(anchors).reshape(-1, 2)\n",
        "\n",
        "    def generate(self):\n",
        "        model_path = os.path.expanduser(self.model_path)\n",
        "        assert model_path.endswith('.h5'), 'Keras model or weights must be a .h5 file.'\n",
        "\n",
        "        # Load model, or construct model and load weights.\n",
        "        num_anchors = len(self.anchors)\n",
        "        num_classes = len(self.class_names)\n",
        "        is_tiny_version = num_anchors==6 # default setting\n",
        "        try:\n",
        "            self.yolo_model = load_model(model_path, compile=False)\n",
        "        except:\n",
        "            self.yolo_model = tiny_yolo_body(Input(shape=(None,None,3)), num_anchors//2, num_classes) \\\n",
        "                if is_tiny_version else yolo_body(Input(shape=(None,None,3)), num_anchors//3, num_classes)\n",
        "            self.yolo_model.load_weights(self.model_path) # make sure model, anchors and classes match\n",
        "        else:\n",
        "            assert self.yolo_model.layers[-1].output_shape[-1] == \\\n",
        "                num_anchors/len(self.yolo_model.output) * (num_classes + 5), \\\n",
        "                'Mismatch between model and given anchor and class sizes'\n",
        "\n",
        "        print('{} model, anchors, and classes loaded.'.format(model_path))\n",
        "\n",
        "        # Generate colors for drawing bounding boxes.\n",
        "        hsv_tuples = [(x / len(self.class_names), 1., 1.)\n",
        "                      for x in range(len(self.class_names))]\n",
        "        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
        "        self.colors = list(\n",
        "            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
        "                self.colors))\n",
        "        np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
        "        np.random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\n",
        "        np.random.seed(None)  # Reset seed to default.\n",
        "\n",
        "        # Generate output tensor targets for filtered bounding boxes.\n",
        "        self.input_image_shape = K.placeholder(shape=(2, ))\n",
        "        if self.gpu_num>=2:\n",
        "            self.yolo_model = multi_gpu_model(self.yolo_model, gpus=self.gpu_num)\n",
        "        boxes, scores, classes = yolo_eval(self.yolo_model.output, self.anchors,\n",
        "                len(self.class_names), self.input_image_shape,\n",
        "                score_threshold=self.score, iou_threshold=self.iou)\n",
        "        return boxes, scores, classes\n",
        "\n",
        "    def detect_image(self, image):\n",
        "        start = timer()\n",
        "\n",
        "        if self.model_image_size != (None, None):\n",
        "            assert self.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
        "            assert self.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
        "            boxed_image = letterbox_image(image, tuple(reversed(self.model_image_size)))\n",
        "        else:\n",
        "            new_image_size = (image.width - (image.width % 32),\n",
        "                              image.height - (image.height % 32))\n",
        "            boxed_image = letterbox_image(image, new_image_size)\n",
        "        image_data = np.array(boxed_image, dtype='float32')\n",
        "\n",
        "        print(image_data.shape)\n",
        "        image_data /= 255.\n",
        "        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
        "\n",
        "        out_boxes, out_scores, out_classes = self.sess.run(\n",
        "            [self.boxes, self.scores, self.classes],\n",
        "            feed_dict={\n",
        "                self.yolo_model.input: image_data,\n",
        "                self.input_image_shape: [image.size[1], image.size[0]],\n",
        "                K.learning_phase(): 0\n",
        "            })\n",
        "\n",
        "        print('Found {} boxes for {}'.format(len(out_boxes), 'img'))\n",
        "\n",
        "        font = ImageFont.truetype(font='font/FiraMono-Medium.otf',\n",
        "                    size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
        "        thickness = (image.size[0] + image.size[1]) // 300\n",
        "\n",
        "        for i, c in reversed(list(enumerate(out_classes))):\n",
        "            predicted_class = self.class_names[c]\n",
        "            box = out_boxes[i]\n",
        "            score = out_scores[i]\n",
        "\n",
        "            label = '{} {:.2f}'.format(predicted_class, score)\n",
        "            draw = ImageDraw.Draw(image)\n",
        "            label_size = draw.textsize(label, font)\n",
        "\n",
        "            top, left, bottom, right = box\n",
        "            top = max(0, np.floor(top + 0.5).astype('int32'))\n",
        "            left = max(0, np.floor(left + 0.5).astype('int32'))\n",
        "            bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
        "            right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
        "            print(label, (left, top), (right, bottom))\n",
        "\n",
        "            if top - label_size[1] >= 0:\n",
        "                text_origin = np.array([left, top - label_size[1]])\n",
        "            else:\n",
        "                text_origin = np.array([left, top + 1])\n",
        "\n",
        "            # My kingdom for a good redistributable image drawing library.\n",
        "            for i in range(thickness):\n",
        "                draw.rectangle(\n",
        "                    [left + i, top + i, right - i, bottom - i],\n",
        "                    outline=self.colors[c])\n",
        "            draw.rectangle(\n",
        "                [tuple(text_origin), tuple(text_origin + label_size)],\n",
        "                fill=self.colors[c])\n",
        "            draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
        "            del draw\n",
        "\n",
        "        end = timer()\n",
        "        print(end - start)\n",
        "        return image\n",
        "\n",
        "    def close_session(self):\n",
        "        self.sess.close()\n",
        "\n",
        "def detect_video(yolo, video_path, output_path=\"\"):\n",
        "    import cv2\n",
        "    vid = cv2.VideoCapture(video_path)\n",
        "    if not vid.isOpened():\n",
        "        raise IOError(\"Couldn't open webcam or video\")\n",
        "    video_FourCC    = int(vid.get(cv2.CAP_PROP_FOURCC))\n",
        "    video_fps       = vid.get(cv2.CAP_PROP_FPS)\n",
        "    video_size      = (int(vid.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "                        int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "    isOutput = True if output_path != \"\" else False\n",
        "    if isOutput:\n",
        "        print(\"!!! TYPE:\", type(output_path), type(video_FourCC), type(video_fps), type(video_size))\n",
        "        out = cv2.VideoWriter(output_path, video_FourCC, video_fps, video_size)\n",
        "    accum_time = 0\n",
        "    curr_fps = 0\n",
        "    fps = \"FPS: ??\"\n",
        "    prev_time = timer()\n",
        "    while True:\n",
        "        return_value, frame = vid.read()\n",
        "        image = Image.fromarray(frame)\n",
        "        image = yolo.detect_image(image)\n",
        "        result = np.asarray(image)\n",
        "        curr_time = timer()\n",
        "        exec_time = curr_time - prev_time\n",
        "        prev_time = curr_time\n",
        "        accum_time = accum_time + exec_time\n",
        "        curr_fps = curr_fps + 1\n",
        "        if accum_time > 1:\n",
        "            accum_time = accum_time - 1\n",
        "            fps = \"FPS: \" + str(curr_fps)\n",
        "            curr_fps = 0\n",
        "        cv2.putText(result, text=fps, org=(3, 15), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                    fontScale=0.50, color=(255, 0, 0), thickness=2)\n",
        "        cv2.namedWindow(\"result\", cv2.WINDOW_NORMAL)\n",
        "        cv2.imshow(\"result\", result)\n",
        "        if isOutput:\n",
        "            out.write(result)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "    yolo.close_session()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    t0 = timer()\n",
        "    yolo=YOLO() #進行YOLO初始化\n",
        "    path = 'VOC2007/JPEGImages/img_1550.jpg' #指定待測影像檔案路徑及名稱\n",
        "    try:\n",
        "        t1 = timer()\n",
        "        image = Image.open(path) #開啟待推論影像\n",
        "    except:\n",
        "        print('Open Error! Try again!')\n",
        "    else:       \n",
        "        print('Start detect object.\\n')\n",
        "        t2 = timer()\n",
        "        r_image = yolo.detect_image(image) #進行推論\n",
        "        t3 = timer()            \n",
        "        r_image.show() #顯示有標示物件框的結果影像\n",
        "        print('Yolo inital: %f sec' %(t1-t0)) #計算及顯示YOLO初始化時間\n",
        "        print('Image load: %f sec' %(t2-t1)) #計算及顯示影像載入時間\n",
        "        print('Detect object: %f sec\\n' %(t3-t2)) #計算偵測物件時間\n",
        "\n",
        "    yolo.close_session() #結束YOLO工作"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}